{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024800.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454342.9447852761"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438900.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165171.13154429477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9114147489539749"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score\n",
    "y_true = [3, -0.5, 2, 7, 4.2]\n",
    "y_pred = [2.5, 0.0, 2, 8, 5.3]\n",
    "performance_metric(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO: Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(prices, features, test_size=0.2, random_state=0)\n",
    "\n",
    "# Success\n",
    "print \"Training and testing split was successful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>6.209</td>\n",
       "      <td>13.22</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>5.427</td>\n",
       "      <td>18.14</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>5.349</td>\n",
       "      <td>19.77</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>6.380</td>\n",
       "      <td>23.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>6.552</td>\n",
       "      <td>3.76</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.927</td>\n",
       "      <td>9.22</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>6.471</td>\n",
       "      <td>17.12</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>5.852</td>\n",
       "      <td>29.97</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>6.129</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>6.242</td>\n",
       "      <td>10.74</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>5.983</td>\n",
       "      <td>18.07</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.290</td>\n",
       "      <td>4.67</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>7.420</td>\n",
       "      <td>6.47</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.682</td>\n",
       "      <td>10.21</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4.973</td>\n",
       "      <td>12.64</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>7.249</td>\n",
       "      <td>4.81</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6.563</td>\n",
       "      <td>5.68</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>6.316</td>\n",
       "      <td>5.68</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>6.824</td>\n",
       "      <td>22.74</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>7.393</td>\n",
       "      <td>16.74</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5.879</td>\n",
       "      <td>17.58</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>8.247</td>\n",
       "      <td>3.95</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>7.107</td>\n",
       "      <td>8.61</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>6.202</td>\n",
       "      <td>14.52</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>6.405</td>\n",
       "      <td>19.37</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>6.411</td>\n",
       "      <td>15.02</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>6.250</td>\n",
       "      <td>5.50</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>6.167</td>\n",
       "      <td>16.29</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.602</td>\n",
       "      <td>16.20</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>5.782</td>\n",
       "      <td>15.94</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>6.854</td>\n",
       "      <td>2.98</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.065</td>\n",
       "      <td>5.52</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>6.874</td>\n",
       "      <td>4.61</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.599</td>\n",
       "      <td>16.51</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>6.402</td>\n",
       "      <td>11.32</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>6.635</td>\n",
       "      <td>5.99</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>5.093</td>\n",
       "      <td>29.68</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>6.860</td>\n",
       "      <td>6.92</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>5.983</td>\n",
       "      <td>13.35</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.595</td>\n",
       "      <td>4.32</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>6.975</td>\n",
       "      <td>4.56</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>6.431</td>\n",
       "      <td>5.08</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>5.155</td>\n",
       "      <td>20.08</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>7.007</td>\n",
       "      <td>5.50</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>5.414</td>\n",
       "      <td>23.97</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6.417</td>\n",
       "      <td>6.72</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.121</td>\n",
       "      <td>8.44</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>6.982</td>\n",
       "      <td>4.86</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>6.487</td>\n",
       "      <td>5.90</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>6.315</td>\n",
       "      <td>7.60</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>5.951</td>\n",
       "      <td>17.92</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.004</td>\n",
       "      <td>17.10</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>6.649</td>\n",
       "      <td>23.24</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>6.162</td>\n",
       "      <td>7.43</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>7.203</td>\n",
       "      <td>9.59</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>6.310</td>\n",
       "      <td>6.75</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>7.274</td>\n",
       "      <td>6.62</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.021</td>\n",
       "      <td>10.30</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6.030</td>\n",
       "      <td>18.80</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>6.020</td>\n",
       "      <td>10.11</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RM  LSTAT  PTRATIO\n",
       "447  6.209  13.22     20.2\n",
       "457  5.427  18.14     20.2\n",
       "386  5.349  19.77     20.2\n",
       "361  6.380  23.69     20.2\n",
       "221  6.552   3.76     17.4\n",
       "59   5.927   9.22     19.7\n",
       "378  6.471  17.12     20.2\n",
       "382  5.852  29.97     20.2\n",
       "154  6.129  15.12     14.7\n",
       "463  6.242  10.74     20.2\n",
       "474  5.983  18.07     20.1\n",
       "65   6.290   4.67     16.1\n",
       "295  7.420   6.47     18.4\n",
       "45   5.682  10.21     17.9\n",
       "299  4.973  12.64     18.4\n",
       "55   7.249   4.81     17.9\n",
       "179  6.563   5.68     17.8\n",
       "322  6.316   5.68     20.2\n",
       "402  6.824  22.74     20.2\n",
       "436  7.393  16.74     20.2\n",
       "124  5.879  17.58     19.1\n",
       "225  8.247   3.95     17.4\n",
       "191  7.107   8.61     12.6\n",
       "410  6.202  14.52     20.2\n",
       "379  6.405  19.37     20.2\n",
       "403  6.411  15.02     20.2\n",
       "160  6.250   5.50     14.7\n",
       "453  6.167  16.29     20.2\n",
       "49   5.602  16.20     17.9\n",
       "306  5.782  15.94     18.4\n",
       "..     ...    ...      ...\n",
       "265  6.854   2.98     17.6\n",
       "72   6.065   5.52     19.2\n",
       "333  6.874   4.61     17.6\n",
       "25   5.599  16.51     21.0\n",
       "165  6.402  11.32     14.7\n",
       "337  6.635   5.99     17.0\n",
       "473  5.093  29.68     20.1\n",
       "174  6.860   6.92     16.6\n",
       "475  5.983  13.35     20.1\n",
       "39   6.595   4.32     18.3\n",
       "193  6.975   4.56     17.0\n",
       "314  6.431   5.08     19.6\n",
       "396  5.155  20.08     20.2\n",
       "88   7.007   5.50     17.8\n",
       "472  5.414  23.97     20.1\n",
       "70   6.417   6.72     19.2\n",
       "87   6.121   8.44     18.5\n",
       "292  6.982   4.86     16.1\n",
       "242  6.487   5.90     19.1\n",
       "277  6.315   7.60     16.6\n",
       "211  5.951  17.92     16.4\n",
       "9    6.004  17.10     15.2\n",
       "359  6.649  23.24     20.2\n",
       "195  6.162   7.43     14.7\n",
       "251  7.203   9.59     13.0\n",
       "323  6.310   6.75     20.2\n",
       "192  7.274   6.62     12.6\n",
       "117  6.021  10.30     17.8\n",
       "47   6.030  18.80     17.9\n",
       "172  6.020  10.11     16.6\n",
       "\n",
       "[391 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.834</td>\n",
       "      <td>8.47</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>6.842</td>\n",
       "      <td>6.90</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.403</td>\n",
       "      <td>26.82</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>6.852</td>\n",
       "      <td>19.78</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6.417</td>\n",
       "      <td>8.81</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>6.406</td>\n",
       "      <td>19.52</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>4.903</td>\n",
       "      <td>29.29</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>6.112</td>\n",
       "      <td>12.67</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.163</td>\n",
       "      <td>11.34</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.965</td>\n",
       "      <td>13.83</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>6.223</td>\n",
       "      <td>21.78</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>5.837</td>\n",
       "      <td>15.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>6.041</td>\n",
       "      <td>7.70</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4.628</td>\n",
       "      <td>34.37</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.727</td>\n",
       "      <td>9.42</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5.757</td>\n",
       "      <td>17.31</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.279</td>\n",
       "      <td>11.97</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>6.510</td>\n",
       "      <td>7.39</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>5.807</td>\n",
       "      <td>16.03</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6.739</td>\n",
       "      <td>4.69</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>7.327</td>\n",
       "      <td>11.25</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7.135</td>\n",
       "      <td>4.45</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4.519</td>\n",
       "      <td>36.98</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.850</td>\n",
       "      <td>8.77</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.569</td>\n",
       "      <td>15.10</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>7.645</td>\n",
       "      <td>3.01</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>7.333</td>\n",
       "      <td>7.79</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>7.610</td>\n",
       "      <td>3.11</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>6.395</td>\n",
       "      <td>13.27</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>6.019</td>\n",
       "      <td>12.92</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>6.540</td>\n",
       "      <td>8.65</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>6.380</td>\n",
       "      <td>24.08</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5.019</td>\n",
       "      <td>34.41</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>6.482</td>\n",
       "      <td>7.19</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.888</td>\n",
       "      <td>14.80</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>6.630</td>\n",
       "      <td>4.70</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>6.794</td>\n",
       "      <td>21.24</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.372</td>\n",
       "      <td>11.12</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>6.897</td>\n",
       "      <td>11.38</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>6.968</td>\n",
       "      <td>17.21</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.383</td>\n",
       "      <td>5.77</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>6.081</td>\n",
       "      <td>14.70</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.741</td>\n",
       "      <td>13.15</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>7.686</td>\n",
       "      <td>3.92</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5.961</td>\n",
       "      <td>9.88</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>6.433</td>\n",
       "      <td>9.52</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.012</td>\n",
       "      <td>12.43</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>6.871</td>\n",
       "      <td>6.07</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>6.516</td>\n",
       "      <td>6.36</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>6.415</td>\n",
       "      <td>6.12</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.405</td>\n",
       "      <td>10.63</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.172</td>\n",
       "      <td>19.15</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>5.706</td>\n",
       "      <td>12.43</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.631</td>\n",
       "      <td>29.93</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>5.936</td>\n",
       "      <td>16.94</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>6.701</td>\n",
       "      <td>16.42</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>6.108</td>\n",
       "      <td>6.57</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>6.122</td>\n",
       "      <td>5.98</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>6.120</td>\n",
       "      <td>9.08</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>6.546</td>\n",
       "      <td>5.33</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RM  LSTAT  PTRATIO\n",
       "15   5.834   8.47     21.0\n",
       "250  6.842   6.90     13.0\n",
       "142  5.403  26.82     14.7\n",
       "392  6.852  19.78     20.2\n",
       "90   6.417   8.81     17.8\n",
       "424  6.406  19.52     20.2\n",
       "144  4.903  29.29     14.7\n",
       "348  6.112  12.67     20.2\n",
       "96   6.163  11.34     18.0\n",
       "21   5.965  13.83     21.0\n",
       "362  6.223  21.78     20.2\n",
       "409  5.837  15.69     20.2\n",
       "311  6.041   7.70     19.6\n",
       "395  4.628  34.37     20.2\n",
       "100  6.727   9.42     20.9\n",
       "134  5.757  17.31     21.2\n",
       "76   6.279  11.97     18.7\n",
       "159  6.510   7.39     14.7\n",
       "205  5.807  16.03     18.6\n",
       "186  6.739   4.69     15.2\n",
       "254  7.327  11.25     13.0\n",
       "194  7.135   4.45     17.0\n",
       "397  4.519  36.98     20.2\n",
       "37   5.850   8.77     19.2\n",
       "482  5.569  15.10     19.2\n",
       "272  7.645   3.01     14.9\n",
       "249  7.333   7.79     13.0\n",
       "196  7.610   3.11     14.7\n",
       "346  6.395  13.27     20.2\n",
       "481  6.019  12.92     19.2\n",
       "..     ...    ...      ...\n",
       "331  6.540   8.65     15.9\n",
       "412  6.380  24.08     20.2\n",
       "141  5.019  34.41     21.2\n",
       "268  6.482   7.19     17.6\n",
       "54   5.888  14.80     21.1\n",
       "281  6.630   4.70     19.2\n",
       "360  6.794  21.24     20.2\n",
       "132  6.372  11.12     21.2\n",
       "232  6.897  11.38     16.6\n",
       "363  6.968  17.21     20.2\n",
       "56   6.383   5.77     17.3\n",
       "442  6.081  14.70     20.2\n",
       "60   5.741  13.15     19.7\n",
       "220  7.686   3.92     17.4\n",
       "71   5.961   9.88     19.2\n",
       "240  6.433   9.52     19.1\n",
       "6    6.012  12.43     15.2\n",
       "289  6.871   6.07     14.8\n",
       "336  6.516   6.36     17.9\n",
       "313  6.415   6.12     19.6\n",
       "102  6.405  10.63     20.9\n",
       "7    6.172  19.15     15.2\n",
       "320  5.706  12.43     16.9\n",
       "8    5.631  29.93     15.2\n",
       "440  5.936  16.94     20.2\n",
       "443  6.701  16.42     20.2\n",
       "246  6.108   6.57     16.4\n",
       "300  6.122   5.98     18.4\n",
       "485  6.120   9.08     21.0\n",
       "171  6.546   5.33     16.6\n",
       "\n",
       "[98 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "params = {'max_depth': [x+1 for x in range(10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(X_train.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShuffleSplit(391, n_iter=10, test_size=0.2, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(performance_metric)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scoring_fnc = make_scorer(performance_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = np.array([[1,0,3,0],[0,6,0,8],[0,10,11,0],[13,0,0,16]])\n",
    "c = np.array([[2],[5],[4],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14],\n",
       "       [38],\n",
       "       [94],\n",
       "       [42]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_words(s, n):\n",
    "    for i in s:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_words(\"betty bought a bit of butter but the butter was bitter\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"betty bought a bit of butter but the butter was bitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betty\n",
      "bought\n",
      "a\n",
      "bit\n",
      "of\n",
      "butter\n",
      "but\n",
      "the\n",
      "butter\n",
      "was\n",
      "bitter\n"
     ]
    }
   ],
   "source": [
    "for i in s.split():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['betty',\n",
       " 'bought',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'butter',\n",
       " 'but',\n",
       " 'the',\n",
       " 'butter',\n",
       " 'was',\n",
       " 'bitter']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 betty\n",
      "1 bought\n",
      "1 a\n",
      "1 bit\n",
      "1 of\n",
      "2 butter\n",
      "1 but\n",
      "1 the\n",
      "2 butter\n",
      "1 was\n",
      "1 bitter\n"
     ]
    }
   ],
   "source": [
    "t = ''\n",
    "co = []\n",
    "for i in s.split():\n",
    "    print s.split().count(i), i\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = ('betty', 'bought', 'a', 'bit', 'of', 'butter', 'but', 'the', 'butter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'betty bought a bit of butter but the butter was bitter'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['betty', 'bought', 'a', 'bit', 'of', 'butter', 'but', 'the', 'butter']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-38ad8a3ff799>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-38ad8a3ff799>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (x for x in s.split(), y in s.split().count(x))\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(x for x in s.split(), y in s.split().count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in s.split():\n",
    "    (x,y) = i, s.split().count(i)\n",
    "    t.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1),\n",
       " ('of', 1),\n",
       " ('bit', 1),\n",
       " ('betty', 1),\n",
       " ('but', 1),\n",
       " ('was', 1),\n",
       " ('bitter', 1),\n",
       " ('the', 1),\n",
       " ('butter', 2),\n",
       " ('bought', 1)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = list(set(t))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.sort(key=lambda tup: tup[1] )\n",
    "t.sort(key = lambda tup: tup[1],  reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.sort(key=lambda tup: tup[1] and tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n = []\n",
    "for i in range(3):\n",
    "    top_n.append( t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1),\n",
       " ('betty', 1),\n",
       " ('bit', 1),\n",
       " ('bitter', 1),\n",
       " ('bought', 1),\n",
       " ('but', 1),\n",
       " ('butter', 2),\n",
       " ('of', 1),\n",
       " ('the', 1),\n",
       " ('was', 1)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 1),\n",
       " ('betty', 1),\n",
       " ('bit', 1),\n",
       " ('bitter', 1),\n",
       " ('bought', 1),\n",
       " ('but', 1),\n",
       " ('butter', 2),\n",
       " ('of', 1),\n",
       " ('the', 1),\n",
       " ('was', 1)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 3), ('bat', 2), ('mat', 1)]\n",
      "[('cat', 3), ('bat', 2), ('mat', 1)]\n",
      "[('butter', 2), ('a', 1), ('of', 1), ('bit', 1), ('betty', 1), ('but', 1), ('was', 1), ('bitter', 1), ('the', 1), ('bought', 1)]\n",
      "[('butter', 2), ('a', 1), ('of', 1)]\n"
     ]
    }
   ],
   "source": [
    "def count_words(s, n):\n",
    "    \"\"\"Return the n most frequently occuring words in s.\"\"\"\n",
    "    \n",
    "    # TODO: Count the number of occurences of each word in s\n",
    "    t = []\n",
    "    for i in s.split():\n",
    "        (x,y) = i, s.split().count(i)\n",
    "        t.append((x,y))\n",
    "    t = list(set(t))\n",
    "    # TODO: Sort the occurences in descending order (alphabetically in case of ties)\n",
    "    t.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    # TODO: Return the top n words as a list of tuples (<word>, <count>)\n",
    "    top_n = []\n",
    "    for i in range(3):\n",
    "        top_n.append( t[i])\n",
    "    return top_n\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    \"\"\"Test count_words() with some inputs.\"\"\"\n",
    "    print count_words(\"cat bat mat cat bat cat\", 3)\n",
    "    print count_words(\"betty bought a bit of butter but the butter was bitter\", 3)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted 5 nearest neighbors price for home 1 is: $372,540.00\n",
      "The predicted 5 nearest neighbors price for home 2 is: $162,120.00\n",
      "The predicted 5 nearest neighbors price for home 3 is: $897,120.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "num_neighbors=5\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "def nearest_neighbor_price(x):\n",
    "    def find_nearest_neighbor_indexes(x, X):  # x is your vector and X is the data set.\n",
    "        neigh = NearestNeighbors( num_neighbors )\n",
    "        neigh.fit(X)\n",
    "        distance, indexes = neigh.kneighbors( [x] )\n",
    "        return indexes\n",
    "    indexes = find_nearest_neighbor_indexes(x, features)\n",
    "    sum_prices = []\n",
    "    for i in indexes:\n",
    "        sum_prices.append(prices[i])\n",
    "    neighbor_avg = np.mean(sum_prices)\n",
    "    return neighbor_avg\n",
    "index = 0  \n",
    "for i in client_data:\n",
    "    val=nearest_neighbor_price(i)\n",
    "    index += 1\n",
    "    print \"The predicted {} nearest neighbors price for home {} is: ${:,.2f}\".format(num_neighbors,index, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 18.5165644172 22.0\n"
     ]
    }
   ],
   "source": [
    "print features['PTRATIO'].min(), features['PTRATIO'].mean(), features['PTRATIO'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $418,935.62\n",
      "Predicted selling price for Client 2's home: $189,123.53\n",
      "Predicted selling price for Client 3's home: $942,666.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "# TODO: Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, test_size=0.2, random_state=0)\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # TODO: Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth': [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid = GridSearchCV(regressor, params, scoring=scoring_fnc, cv =cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_\n",
    "reg = fit_model(X_train, y_train)\n",
    "client_data = [[6, 12, 18], # Client 1\n",
    "               [4, 37, 22], # Client 2\n",
    "               [8, 2, 12]]  # Client 3\n",
    "for i, price in enumerate(reg.predict(client_data)):\n",
    "    print \"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: $418,935.62\n",
      "Trial 2: $464,562.00\n",
      "Trial 3: $437,966.67\n",
      "Trial 4: $424,416.18\n",
      "Trial 5: $466,935.00\n",
      "Trial 6: $437,007.41\n",
      "Trial 7: $431,953.85\n",
      "Trial 8: $436,522.06\n",
      "Trial 9: $431,907.00\n",
      "Trial 10: $435,069.23\n",
      "\n",
      "Range in prices: $47,999.38\n"
     ]
    }
   ],
   "source": [
    "vs.PredictTrials(features, prices, fit_model, client_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
